import streamlit as st
import time
from pathlib import Path
import sys

sys.path.append(str(Path(__file__).parent / "core"))

from core.config import config_manager
from core.inference_engine import inference_engine
from core.queue_manager import generation_queue
from core.generation_params import GenerationParams
from core.utils.image_utils import load_image, create_comparison_image

# Configuration de la page
st.set_page_config(
    page_title="Floor Plan Generator",
    page_icon="üè†",
    layout="wide",
    initial_sidebar_state="expanded"
)

# Styles CSS personnalis√©s
st.markdown("""
<style>
    .main-header {
        font-size: 2.5rem;
        color: #1f77b4;
        text-align: center;
        margin-bottom: 2rem;
    }
    
    .status-box {
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
    
    .status-pending {
        background-color: #fff3cd;
        border: 1px solid #ffeaa7;
        color: #856404;
    }
    
    .status-processing {
        background-color: #cce5ff;
        border: 1px solid #74b9ff;
        color: #004085;
    }
    
    .status-completed {
        background-color: #d4edda;
        border: 1px solid #00b894;
        color: #155724;
    }
    
    .status-failed {
        background-color: #f8d7da;
        border: 1px solid #e74c3c;
        color: #721c24;
    }
    
    .model-info {
        background-color: #f8f9fa;
        padding: 1rem;
        border-radius: 0.5rem;
        margin: 1rem 0;
    }
</style>
""", unsafe_allow_html=True)

def initialize_app():
    """Initialise l'application"""
    if 'initialized' not in st.session_state:
        st.session_state.initialized = False
    
    if not st.session_state.initialized:
        with st.spinner("üöÄ Initialisation de l'application..."):
            # Cr√©er les dossiers n√©cessaires
            config_manager.create_directories()
            
            # Configurer la file d'attente
            generation_queue.set_generation_function(inference_engine.generate)
            generation_queue.start()
            
            st.session_state.initialized = True
            st.success("‚úÖ Application initialis√©e avec succ√®s!")

def render_sidebar():
    """Rendu de la sidebar avec les param√®tres"""
    st.sidebar.title("‚öôÔ∏è Param√®tres de G√©n√©ration")
    
    # S√©lection du mod√®le de base
    base_models = config_manager.get_base_models()
    default_model = config_manager.get_default_base_model() or list(base_models.keys())[0]
    
    base_model = st.sidebar.selectbox(
        "Mod√®le de base",
        options=list(base_models.keys()),
        index=list(base_models.keys()).index(default_model) if default_model in base_models else 0
    )
    
    # S√©lection de l'approche
    approach = st.sidebar.selectbox(
        "Approche de g√©n√©ration",
        options=["single_lora", "combined_approach"],
        format_func=lambda x: {
            "single_lora": "LoRA Simple",
            "combined_approach": "Approche Combin√©e (Wall + ControlNet + Plan)"
        }[x]
    )
    
    # S√©lection du LoRA (pour single_lora)
    lora_models = config_manager.get_lora_models()
    lora_model = None
    
    if approach == "single_lora":
        lora_options = [k for k in lora_models.keys() if k != "wall_lora"]
        lora_model = st.sidebar.selectbox(
            "Mod√®le LoRA",
            options=lora_options
        )
    
    st.sidebar.markdown("---")
    
    # Param√®tres de sampling
    st.sidebar.subheader("üéØ Param√®tres de Sampling")
    
    defaults = config_manager.get_generation_defaults()
    
    steps = st.sidebar.slider(
        "Nombre de steps",
        min_value=10,
        max_value=50,
        value=defaults.steps,
        step=1
    )
    
    cfg_scale = st.sidebar.slider(
        "CFG Scale",
        min_value=1.0,
        max_value=15.0,
        value=defaults.cfg_scale,
        step=0.1
    )
    
    samplers = config_manager.get_samplers()
    sampler = st.sidebar.selectbox(
        "Sampler",
        options=samplers,
        index=samplers.index(defaults.sampler) if defaults.sampler in samplers else 0
    )
    
    seed = st.sidebar.number_input(
        "Seed (-1 pour al√©atoire)",
        value=-1,
        min_value=-1,
        max_value=2**32-1
    )
    
    st.sidebar.markdown("---")
    
    # Param√®tres LoRA
    st.sidebar.subheader("üîß Param√®tres LoRA")
    
    if approach == "single_lora":
        lora_weight = st.sidebar.slider(
            "Poids LoRA",
            min_value=0.1,
            max_value=2.0,
            value=0.8,
            step=0.1
        )
        wall_lora_weight = 0.7
        plan_lora_weight = 0.8
        controlnet_weight = 1.0
    else:
        lora_weight = 0.8
        wall_lora_weight = st.sidebar.slider(
            "Poids Wall LoRA",
            min_value=0.1,
            max_value=2.0,
            value=0.7,
            step=0.1
        )
        plan_lora_weight = st.sidebar.slider(
            "Poids Plan LoRA",
            min_value=0.1,
            max_value=2.0,
            value=0.8,
            step=0.1
        )
        controlnet_weight = st.sidebar.slider(
            "Poids ControlNet",
            min_value=0.1,
            max_value=2.0,
            value=1.0,
            step=0.1
        )
    
    st.sidebar.markdown("---")
    
    # Param√®tres d'image
    st.sidebar.subheader("üñºÔ∏è Param√®tres d'Image")
    
    col1, col2 = st.sidebar.columns(2)
    with col1:
        width = st.selectbox(
            "Largeur",
            options=[512, 768, 1024],
            index=2
        )
    with col2:
        height = st.selectbox(
            "Hauteur", 
            options=[512, 768, 1024],
            index=2
        )
    
    batch_size = st.sidebar.slider(
        "Batch Size",
        min_value=1,
        max_value=4,
        value=1
    )
    
    # Cr√©er l'objet de param√®tres
    params = GenerationParams(
        prompt="",  # Sera rempli plus tard
        base_model=base_model,
        approach=approach,
        lora_model=lora_model,
        steps=steps,
        cfg_scale=cfg_scale,
        sampler=sampler,
        seed=seed,
        width=width,
        height=height,
        batch_size=batch_size,
        lora_weight=lora_weight,
        wall_lora_weight=wall_lora_weight,
        plan_lora_weight=plan_lora_weight,
        controlnet_weight=controlnet_weight
    )
    
    return params

def render_prompt_section():
    """Rendu de la section de prompt"""
    st.subheader("üìù Configuration du Prompt")
    
    # Templates de prompts
    templates = config_manager.get_prompt_templates()
    room_types = config_manager.get_room_types()
    
    col1, col2 = st.columns([2, 1])
    
    with col1:
        # S√©lection du template
        template_names = list(templates.keys())
        selected_template = st.selectbox(
            "Template de prompt",
            options=["custom"] + template_names,
            format_func=lambda x: "Personnalis√©" if x == "custom" else x.replace("_", " ").title()
        )
        
        if selected_template != "custom":
            # S√©lection du type de pi√®ce
            room_type = st.selectbox(
                "Type de pi√®ce",
                options=room_types
            )
            
            # G√©n√©rer le prompt √† partir du template
            template_prompt = templates[selected_template].format(room_type=room_type)
            st.text_area(
                "Prompt g√©n√©r√©",
                value=template_prompt,
                height=80,
                disabled=True
            )
        else:
            template_prompt = ""
            room_type = ""
    
    with col2:
        st.markdown("**üí° Conseils pour les prompts:**")
        st.markdown("""
        - Soyez pr√©cis sur le type de pi√®ce
        - Mentionnez le style architectural
        - Incluez "floor plan"
        """)
    
    # Prompt principal
    if selected_template != "custom":
        prompt = st.text_area(
            "Prompt personnalis√© (optionnel)",
            value="",
            height=100,
            placeholder="Ajoutez des d√©tails suppl√©mentaires au template..."
        )
        
        # Combiner template et prompt personnalis√©
        if prompt.strip():
            final_prompt = f"{template_prompt}, {prompt}"
        else:
            final_prompt = template_prompt
    else:
        final_prompt = st.text_area(
            "Prompt personnalis√©",
            value="",
            height=100,
            placeholder="Entrez votre prompt personnalis√©..."
        )
    
    # Prompt n√©gatif
    default_negative = ""
    
    negative_prompt = st.text_area(
        "Prompt n√©gatif",
        value=default_negative,
        height=80
    )
    
    return final_prompt, negative_prompt

def render_generation_section(params):
    """Rendu de la section de g√©n√©ration"""
    st.subheader("üé® G√©n√©ration d'Image")
    
    prompt, negative_prompt = render_prompt_section()
    
    # Mise √† jour des param√®tres avec les prompts
    params.prompt = prompt
    params.negative_prompt = negative_prompt
    
    col1, col2, col3 = st.columns([2, 1, 1])
    
    with col1:
        generate_button = st.button(
            "üöÄ G√©n√©rer l'image",
            type="primary",
            disabled=not prompt.strip()
        )
    
    with col2:
        if st.button("üìä Statistiques"):
            stats = generation_queue.get_stats()
            st.json(stats)
    
    with col3:
        if st.button("üßπ Nettoyer"):
            generation_queue.clear_completed()
            st.success("‚úÖ T√¢ches termin√©es supprim√©es")
    
    if generate_button and prompt.strip():
        if not params.validate():
            st.error("‚ùå Param√®tres invalides")
            return
        
        # Soumettre la g√©n√©ration
        task_id = generation_queue.submit_generation(params)
        st.session_state.current_task_id = task_id
        st.success(f"‚úÖ G√©n√©ration soumise (ID: {task_id[:8]})")
        
        # Rerun pour afficher le suivi
        st.rerun()

def render_task_monitoring():
    """Rendu du suivi des t√¢ches"""
    if 'current_task_id' not in st.session_state:
        return
    
    task_id = st.session_state.current_task_id
    result = generation_queue.get_result(task_id)
    
    if not result:
        return
    
    st.subheader("üìà Suivi de la G√©n√©ration")
    
    # Barre de statut
    status_colors = {
        "pending": "üü°",
        "processing": "üîµ", 
        "completed": "üü¢",
        "failed": "üî¥"
    }
    
    status_text = {
        "pending": "En attente",
        "processing": "En cours de traitement",
        "completed": "Termin√©",
        "failed": "√âchou√©"
    }
    
    col1, col2, col3 = st.columns([1, 2, 1])
    
    with col1:
        st.metric("Statut", f"{status_colors[result.status]} {status_text[result.status]}")
    
    with col2:
        if result.start_time:
            st.metric("Dur√©e", result.get_duration_str())
    
    with col3:
        queue_size = generation_queue.get_queue_size()
        st.metric("File d'attente", f"{queue_size} t√¢ches")
    
    # D√©tails de la t√¢che
    with st.expander("üìã D√©tails de la t√¢che"):
        st.json({
            "id": result.id,
            "approach": result.params.approach,
            "model": result.params.base_model,
            "lora": result.params.lora_model,
            "steps": result.params.steps,
            "cfg_scale": result.params.cfg_scale,
            "seed": result.params.seed,
            "dimensions": f"{result.params.width}x{result.params.height}"
        })
    
    # Affichage du r√©sultat
    if result.status == "completed" and result.image_path:
        st.subheader("üñºÔ∏è R√©sultat")
        
        image = load_image(result.image_path)
        if image:
            st.image(image, caption=f"G√©n√©r√© en {result.get_duration_str()}")
            
            # Boutons d'action
            col1, col2, col3 = st.columns(3)
            
            with col1:
                if st.button("üíæ Sauvegarder vers S3"):
                    try:
                        # Upload vers S3
                        s3_url = inference_engine.upload_to_s3(result)
                        if s3_url:
                            st.success(f"‚úÖ Image upload√©e vers S3: {s3_url}")
                            result.s3_url = s3_url
                        else:
                            st.error("‚ùå Erreur lors de l'upload S3")
                    except Exception as e:
                        st.error(f"‚ùå Erreur S3: {e}")
            
            with col2:
                if st.button("üîÑ R√©g√©n√©rer"):
                    # R√©g√©n√©rer avec les m√™mes param√®tres
                    new_params = result.params
                    new_params.seed = -1  # Nouveau seed al√©atoire
                    new_task_id = generation_queue.submit_generation(new_params)
                    st.session_state.current_task_id = new_task_id
                    st.rerun()
            
            with col3:
                if st.button("üìä Comparer"):
                    st.session_state.comparison_image = result.image_path
                    st.success("Image ajout√©e √† la comparaison")
    
    elif result.status == "failed":
        st.error(f"‚ùå G√©n√©ration √©chou√©e: {result.error_message}")
    
    elif result.status == "processing":
        st.info("üîÑ G√©n√©ration en cours...")
        # Auto-refresh toutes les 2 secondes
        time.sleep(2)
        st.rerun()

def render_model_info():
    """Rendu des informations sur les mod√®les"""
    st.subheader("‚ÑπÔ∏è Informations sur les Mod√®les")
    
    model_info = inference_engine.get_model_info()
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.markdown("**Mod√®les de Base:**")
        for name, info in model_info["base_models"].items():
            status = "‚úÖ" if info["available"] else "‚ùå"
            st.markdown(f"- {status} {name}")
        
        st.markdown("**Mod√®les LoRA:**")
        for name, info in model_info["lora_models"].items():
            status = "‚úÖ" if info["available"] else "‚ùå"
            st.markdown(f"- {status} {name}")
    
    with col2:
        st.markdown("**Informations Syst√®me:**")
        st.markdown(f"- Device: {model_info['device']}")
        
        if "gpu_name" in model_info["memory_info"]:
            memory_info = model_info["memory_info"]
            st.markdown(f"- GPU: {memory_info['gpu_name']}")
            st.markdown(f"- M√©moire GPU utilis√©e: {memory_info['gpu_memory_allocated']:.1f} GB")
            st.markdown(f"- M√©moire GPU r√©serv√©e: {memory_info['gpu_memory_reserved']:.1f} GB")

def render_recent_generations():
    """Rendu des g√©n√©rations r√©centes"""
    st.subheader("üïí G√©n√©rations R√©centes")
    
    completed_tasks = generation_queue.get_completed_tasks()
    
    if not completed_tasks:
        st.info("Aucune g√©n√©ration termin√©e")
        return
    
    # Trier par date de fin (plus r√©cent en premier)
    sorted_tasks = sorted(
        completed_tasks.items(),
        key=lambda x: x[1].end_time or 0,
        reverse=True
    )
    
    # Afficher les 6 plus r√©centes
    recent_tasks = sorted_tasks[:6]
    
    cols = st.columns(3)
    
    for i, (task_id, result) in enumerate(recent_tasks):
        col = cols[i % 3]
        
        with col:
            if result.image_path:
                image = load_image(result.image_path)
                if image:
                    st.image(image, caption=f"ID: {task_id[:8]}")
                    
                    if st.button(f"üîç Voir d√©tails", key=f"details_{task_id}"):
                        st.session_state.current_task_id = task_id
                        st.rerun()

def main():
    """Fonction principale"""
    st.markdown('<h1 class="main-header">üè† Floor Plan Generator</h1>', unsafe_allow_html=True)
    
    # Initialiser l'application
    initialize_app()
    
    if not st.session_state.initialized:
        return
    
    # Sidebar avec param√®tres
    params = render_sidebar()
    
    # Contenu principal
    tab1, tab2, tab3 = st.tabs(["üé® G√©n√©ration", "üìä Suivi", "‚ÑπÔ∏è Informations"])
    
    with tab1:
        render_generation_section(params)
        render_recent_generations()
    
    with tab2:
        render_task_monitoring()
        
        # Statistiques g√©n√©rales
        st.subheader("üìà Statistiques G√©n√©rales")
        stats = generation_queue.get_stats()
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            st.metric("Total", stats["total_tasks"])
        with col2:
            st.metric("En attente", stats["pending"])
        with col3:
            st.metric("Termin√©es", stats["completed"])
        with col4:
            st.metric("√âchou√©es", stats["failed"])
    
    with tab3:
        render_model_info()
        
        # Nettoyage
        st.subheader("üßπ Maintenance")
        col1, col2 = st.columns(2)
        
        with col1:
            if st.button("üóëÔ∏è Nettoyer anciennes images"):
                from core.utils.image_utils import cleanup_old_images
                cleanup_old_images()
                st.success("‚úÖ Nettoyage effectu√©")
        
        with col2:
            if st.button("üîÑ Red√©marrer file d'attente"):
                generation_queue.stop()
                generation_queue.start()
                st.success("‚úÖ File d'attente red√©marr√©e")

if __name__ == "__main__":
    main()